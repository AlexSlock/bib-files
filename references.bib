@article{palReviewExperimentalEvaluation2022,
  title = {A Review and Experimental Evaluation of Deep Learning Methods for {{MRI}} Reconstruction},
  author = {Pal, Arghya and Rathi, Yogesh},
  date = {2022-03},
  journaltitle = {The journal of machine learning for biomedical imaging},
  shortjournal = {J Mach Learn Biomed Imaging},
  volume = {1},
  eprint = {35722657},
  eprinttype = {pubmed},
  pages = {001},
  issn = {2766-905X},
  abstract = {Following the success of deep learning in a wide range of applications, neural network-based machine-learning techniques have received significant interest for accelerating magnetic resonance imaging (MRI) acquisition and reconstruction strategies. A number of ideas inspired by deep learning techniques for computer vision and image processing have been successfully applied to nonlinear image reconstruction in the spirit of compressed sensing for accelerated MRI. Given the rapidly growing nature of the field, it is imperative to consolidate and summarize the large number of deep learning methods that have been reported in the literature, to obtain a better understanding of the field in general. This article provides an overview of the recent developments in neural-network based approaches that have been proposed specifically for improving parallel imaging. A general background and introduction to parallel MRI is also given from a classical view of k-space based reconstruction methods. Image domain based techniques that introduce improved regularizers are covered along with k-space based methods which focus on better interpolation strategies using neural networks. While the field is rapidly evolving with plenty of papers published each year, in this review, we attempt to cover broad categories of methods that have shown good performance on publicly available data sets. Limitations and open problems are also discussed and recent efforts for producing open data sets and benchmarks for the community are examined.},
  pmcid = {PMC9202830}
}

@article{sonodaNeuralNetworkUnbounded2017,
  title = {Neural Network with Unbounded Activation Functions Is Universal Approximator},
  author = {Sonoda, Sho and Murata, Noboru},
  date = {2017-09-01},
  journaltitle = {Applied and Computational Harmonic Analysis},
  shortjournal = {Applied and Computational Harmonic Analysis},
  volume = {43},
  number = {2},
  pages = {233--268},
  issn = {1063-5203},
  doi = {10.1016/j.acha.2015.12.005},
  abstract = {This paper presents an investigation of the approximation property of neural networks with unbounded activation functions, such as the rectified linear unit (ReLU), which is the new de-facto standard of deep learning. The ReLU network can be analyzed by the ridgelet transform with respect to Lizorkin distributions. By showing three reconstruction formulas by using the Fourier slice theorem, the Radon transform, and Parseval's relation, it is shown that a neural network with unbounded activation functions still satisfies the universal approximation property. As an additional consequence, the ridgelet transform, or the backprojection filter in the Radon domain, is what the network learns after backpropagation. Subject to a constructive admissibility condition, the trained network can be obtained by simply discretizing the ridgelet transform, without backpropagation. Numerical examples not only support the consistency of the admissibility condition but also imply that some non-admissible cases result in low-pass filtering.},
  keywords = {Admissibility condition,Backprojection filter,Bounded extension to,Integral representation,Lizorkin distribution,Neural network,Radon transform,Rectified linear unit (ReLU),Ridgelet transform,Universal approximation},
  file = {C\:\\Users\\geert\\Zotero\\storage\\ZM78BD2D\\Sonoda en Murata - 2017 - Neural network with unbounded activation functions is universal approximator.pdf;C\:\\Users\\geert\\Zotero\\storage\\PV9QUY7X\\S1063520315001748.html}
}
